import json
import os
from pathlib import Path
from aiogram import Bot
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.types import Message
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
QUESTIONNAIRE_FILE = Path(os.getenv("DOCTOR_QUESTIONS"))
client = AsyncOpenAI(api_key=OPENAI_KEY)


class InterviewState(StatesGroup):
    ACTIVE = State()


async def load_questionnaire() -> list[dict]:
    questions = []
    with open(QUESTIONNAIRE_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            questions.append(json.loads(line))
    return questions


async def start_interview(chat_id: int, bot: Bot, state: FSMContext):
    questionnaire = await load_questionnaire()
    if not questionnaire:
        await bot.send_message(chat_id, "–û–ø—Ä–æ—Å–Ω–∏–∫ –ø—É—Å—Ç.")
        return

    await state.clear()
    first_question = questionnaire[0]['question']
    await bot.send_message(chat_id, f"mode4:\n{first_question}")
    await state.update_data(
        current_step=0,
        history=[{"role": "assistant", "content": first_question}],
        awaiting_reply=True,
        bot_instance=bot,
        answers=[]  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –æ—Ç–≤–µ—Ç–æ–≤
    )


async def process_message(message: Message, state: FSMContext):  # –£–±—Ä–∞–ª–∏ bot –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    data = await state.get_data()
    bot = data.get('bot_instance')  # –ü–æ–ª—É—á–∞–µ–º –±–æ—Ç–∞ –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    current_step = data.get('current_step', 0)
    questionnaire = await load_questionnaire()

    if current_step >= len(questionnaire):
        await finish_interview(message, state)
        return

    if data.get('awaiting_reply', False):
        history = data.get('history', []) + [{"role": "user", "content": message.text}]
        await state.update_data(history=history)
        await validate_answer(message, state, questionnaire[current_step])


async def ask_question(message: Message, bot: Bot, state: FSMContext, question_data: dict):
    question_text = f"mode4:\n{question_data['question']}"
    await bot.send_message(message.chat.id, question_text)

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    history = (await state.get_data()).get('history', []) + [{"role": "assistant", "content": question_text}]
    await state.update_data(
        history=history,
        awaiting_reply=True
    )


async def validate_answer(message: Message, state: FSMContext, question_data: dict):
    data = await state.get_data()
    history = data.get('history', [])
    current_step = data['current_step']

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
    dialog_history = "\n".join(
        f"{msg['role']}: {msg['content']}"
        for msg in history
        if msg['role'] in ['user', 'assistant']
    )

    system_msg = {
        "role": "system",
        "content": f"""You are a medical assistant. Analyze the ENTIRE previous dialog:

        Current question: {question_data['question']}
        Required information(if present): {question_data['context']}

        Full dialog:
        {dialog_history}

        1. Check that all needed information is present in the dialog or can be interpreted from user input.
        2. Respond with "STEP_COMPLETE" if ALL criteria are met.
        3. If data is missing, take it as "no" or ask for clarification.
        4. Always Respond in Russian."""
    }

    messages = [system_msg]

    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.5,
        max_tokens=200
    )

    assessment = response.choices[0].message.content.strip()

    print('msg', system_msg, '\n', response, '\n', assessment)

    if assessment == "STEP_COMPLETE":
        await process_valid_answer(message, state)
    else:
        clarification = assessment if assessment else "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ –≤–∞—à –æ—Ç–≤–µ—Ç"
        await message.answer(f"mode4_val:\n{clarification}")

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å —É—Ç–æ—á–Ω–µ–Ω–∏–µ–º
        new_history = history + [
            {"role": "user", "content": message.text},
            {"role": "assistant", "content": clarification}
        ]
        await state.update_data(
            history=new_history,
            awaiting_reply=True
        )


async def process_valid_answer(message: Message, state: FSMContext):
    data = await state.get_data()
    questionnaire = await load_questionnaire()
    current_step = data['current_step']

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
    history = data.get('history', [])
    user_answers = [msg for msg in history if msg['role'] == 'user']
    last_answer = user_answers[-1]['content'] if user_answers else ""

    answers = data.get('answers', [])
    answers.append({
        "question": questionnaire[current_step]['question'],
        "answer": last_answer
    })
    await state.update_data(answers=answers)

    new_step = current_step + 1
    if new_step >= len(questionnaire):
        await finish_interview(message, state)
        return

    bot = data['bot_instance']
    next_question_data = questionnaire[new_step]

    await bot.send_message(
        chat_id=message.chat.id,
        text=f"mode4:\n{next_question_data['question']}"
    )

    new_history = history + [
        {"role": "assistant", "content": next_question_data['question']}
    ]

    await state.update_data(
        current_step=new_step,
        history=new_history,
        awaiting_reply=True
    )


async def generate_medical_report(answers: list[dict]) -> str:
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å –æ—Ç–≤–µ—Ç–∞–º–∏ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        answers_text = "\n".join(
            [f"–í–æ–ø—Ä–æ—Å: {item['question']}\n–û—Ç–≤–µ—Ç: {item['answer']}" for item in answers]
        )

        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": """–í—ã –æ–ø—ã—Ç–Ω—ã–π –≤—Ä–∞—á-—Ç–µ—Ä–∞–ø–µ–≤—Ç. –ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø–∞—Ü–∏–µ–Ω—Ç–∞:
1. –°–æ—Å—Ç–∞–≤—å—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
2. –£–∫–∞–∂–∏—Ç–µ –∂–∞–ª–æ–±—ã –∏ —Å–∏–º–ø—Ç–æ–º—ã
3. –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥–∏–∞–≥–Ω–æ–∑—ã
4. –°–æ—Å—Ç–∞–≤—å—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º
5. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ª–µ—á–µ–Ω–∏—è
–û—Ñ–æ—Ä–º–∏—Ç–µ –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ"""
                },
                {
                    "role": "user",
                    "content": f"–û—Ç–≤–µ—Ç—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞:\n{answers_text}"
                }
            ],
            temperature=0.3,
            max_tokens=1500
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á–µ—Ç"


async def finish_interview(message: Message, state: FSMContext):
    data = await state.get_data()
    answers = data.get('answers', [])

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç—á–µ—Ç
    report = await generate_medical_report(answers)
    await message.answer("mode4:\n‚úÖ –û–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–µ–Ω! –°–ø–∞—Å–∏–±–æ!")
    formatted_report = f"ü©∫   –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ:\n\n{report}"
    await message.answer(formatted_report)
    await state.clear()
