import os
import json
import logging
from pathlib import Path
import asyncio

from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.fsm.storage.memory import MemoryStorage
from dotenv import load_dotenv
from openai import AsyncOpenAI

load_dotenv()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_TOKEN = os.getenv("DOCTOR_SEP_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
QUESTIONNAIRE_FILE = Path(os.getenv("DOCTOR_QUESTIONS"))

client = AsyncOpenAI(api_key=OPENAI_KEY)


# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–ø—Ä–æ—Å–∞
class InterviewState(StatesGroup):
    ACTIVE = State()


# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –æ–ø—Ä–æ—Å–Ω–∏–∫–∞ –∏–∑ —Ñ–∞–π–ª–∞
async def load_questionnaire() -> list:
    questions = []
    with open(QUESTIONNAIRE_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            questions.append(json.loads(line))
    return questions


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start ‚Äì –∑–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–≤—å—é
async def start_interview_handler(message: types.Message, state: FSMContext):
    questionnaire = await load_questionnaire()
    if not questionnaire:
        await message.answer("–û–ø—Ä–æ—Å–Ω–∏–∫ –ø—É—Å—Ç.")
        return

    await state.clear()
    first_question = questionnaire[0]['question']
    await message.answer(f"Answer:\n{first_question}")
    await state.update_data(
        current_step=0,
        history=[{"role": "assistant", "content": first_question}],
        awaiting_reply=True,
        answers=[]
    )


# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤–æ –≤—Ä–µ–º—è –æ–ø—Ä–æ—Å–∞
async def process_message_handler(message: types.Message, state: FSMContext):
    data = await state.get_data()
    if 'current_step' not in data:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ –æ–ø—Ä–æ—Å –∫–æ–º–∞–Ω–¥–æ–π /start")
        return

    current_step = data.get('current_step', 0)
    questionnaire = await load_questionnaire()

    if current_step >= len(questionnaire):
        await finish_interview(message, state)
        return

    if data.get('awaiting_reply', False):
        history = data.get('history', []) + [{"role": "user", "content": message.text}]
        await state.update_data(history=history)
        await validate_answer(message, state, questionnaire[current_step])


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
async def ask_question(message: types.Message, state: FSMContext, question_data: dict):
    question_text = f"mode4:\n{question_data['question']}"
    await message.answer(question_text)
    history = (await state.get_data()).get('history', []) + [{"role": "assistant", "content": question_text}]
    await state.update_data(
        history=history,
        awaiting_reply=True
    )


# –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ OpenAI
async def validate_answer(message: types.Message, state: FSMContext, question_data: dict):
    data = await state.get_data()
    history = data.get('history', [])
    current_step = data.get('current_step', 0)

    dialog_history = "\n".join(
        f"{msg['role']}: {msg['content']}"
        for msg in history
        if msg['role'] in ['user', 'assistant']
    )

    system_msg = {
        "role": "system",
        "content": f"""You are a medical assistant. Analyze the ENTIRE previous dialog:

Current question: {question_data['question']}
Required information(if present): {question_data.get('context', '')}

Full dialog:
{dialog_history}

1. Check if data is absurd or logically incorrect, ask again.
2. Check that all needed information is present in the dialog or can be interpreted from user input.
3. Respond with "STEP_COMPLETE" if ALL criteria are met.
4. If data is missing, take it as "no" or ask for clarification.
5. Always Respond in Russian."""
    }

    messages = [system_msg]

    response = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.5,
        max_tokens=200
    )

    assessment = response.choices[0].message.content.strip()
    print('msg', system_msg)
    print('response:', response)

    if assessment == "STEP_COMPLETE":
        await process_valid_answer(message, state)
    else:
        clarification = assessment if assessment else "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ –≤–∞—à –æ—Ç–≤–µ—Ç"
        await message.answer(f"check:\n{clarification}")
        new_history = history + [
            {"role": "user", "content": message.text},
            {"role": "assistant", "content": clarification}
        ]
        await state.update_data(
            history=new_history,
            awaiting_reply=True
        )


# –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
async def process_valid_answer(message: types.Message, state: FSMContext):
    data = await state.get_data()
    questionnaire = await load_questionnaire()
    current_step = data.get('current_step', 0)
    history = data.get('history', [])
    user_answers = [msg for msg in history if msg['role'] == 'user']
    last_answer = user_answers[-1]['content'] if user_answers else ""
    answers = data.get('answers', [])
    answers.append({
        "question": questionnaire[current_step]['question'],
        "answer": last_answer
    })
    await state.update_data(answers=answers)

    new_step = current_step + 1
    if new_step >= len(questionnaire):
        await finish_interview(message, state)
        return

    next_question_data = questionnaire[new_step]
    await message.answer(f"Answer:\n{next_question_data['question']}")
    new_history = history + [{"role": "assistant", "content": next_question_data['question']}]
    await state.update_data(
        current_step=new_step,
        history=new_history,
        awaiting_reply=True
    )


# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –æ—Ç—á—ë—Ç–∞ —á–µ—Ä–µ–∑ OpenAI
async def generate_medical_report(answers: list) -> str:
    try:
        answers_text = "\n".join(
            [f"–í–æ–ø—Ä–æ—Å: {item['question']}\n–û—Ç–≤–µ—Ç: {item['answer']}" for item in answers]
        )
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": """–í—ã –æ–ø—ã—Ç–Ω—ã–π –≤—Ä–∞—á-—Ç–µ—Ä–∞–ø–µ–≤—Ç. –ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø–∞—Ü–∏–µ–Ω—Ç–∞:
1. –°–æ—Å—Ç–∞–≤—å—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
2. –£–∫–∞–∂–∏—Ç–µ –∂–∞–ª–æ–±—ã –∏ —Å–∏–º–ø—Ç–æ–º—ã
3. –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥–∏–∞–≥–Ω–æ–∑—ã
4. –°–æ—Å—Ç–∞–≤—å—Ç–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º
5. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ª–µ—á–µ–Ω–∏—è
–û—Ñ–æ—Ä–º–∏—Ç–µ –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ"""
                },
                {
                    "role": "user",
                    "content": f"–û—Ç–≤–µ—Ç—ã –ø–∞—Ü–∏–µ–Ω—Ç–∞:\n{answers_text}"
                }
            ],
            temperature=0.3,
            max_tokens=1500
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á–µ—Ç"


# –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤—å—é ‚Äì –æ—Ç–ø—Ä–∞–≤–∫–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞
async def finish_interview(message: types.Message, state: FSMContext):
    data = await state.get_data()
    answers = data.get('answers', [])
    report = await generate_medical_report(answers)
    await message.answer("Answer:\n‚úÖ –û–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–µ–Ω! –°–ø–∞—Å–∏–±–æ!")
    formatted_report = f"ü©∫   –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ:\n\n{report}"
    await message.answer(formatted_report)
    await state.clear()


# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤
async def main():
    logging.basicConfig(level=logging.INFO)
    bot = Bot(token=API_TOKEN)
    storage = MemoryStorage()
    dp = Dispatcher(storage=storage)

    dp.message.register(start_interview_handler, Command(commands=["start"]))
    dp.message.register(process_message_handler, lambda message: message.text is not None)

    async def on_startup():
        print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")

    dp.startup.register(on_startup)

    try:
        await dp.start_polling(bot)
    finally:
        await bot.session.close()


if __name__ == '__main__':
    asyncio.run(main())
